{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hw4 Machine Learning Fall 2018 | Part II - Programming | amc1354 & ads798\n",
    "## Problem 5\n",
    "### (a) List the 5 tokens that occur most frequently in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the most frequent tokens are English stopwords and punctuation. We decided to create a more useful dataset by removing punctuation, English stopwords, and stemming words so we don't have attributes with repeated meaning. E.g., \"love\", \"loved\", \"loving\" would form different attributes. After stemming, they will belong to the same attribute \"lov\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/amc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('movi', 258), ('film', 228), ('one', 130), ('like', 85), ('n', 85)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "trainingcorpus = []\n",
    "for i in range(0, len(dataset)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['review'][i])\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    trainingcorpus.append(review)\n",
    "\n",
    "token_count = Counter(' '.join(trainingcorpus).split()).most_common()\n",
    "\n",
    "print(token_count[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Calculate IG for every attribute and list the 5 attributes with the highest IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature        IG\n",
      "259       bad  0.025357\n",
      "324      best  0.020668\n",
      "2436     move  0.012183\n",
      "2716  perform  0.012123\n",
      "3886    touch  0.011337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import numpy as np\n",
    "def entropy(var):\n",
    "    #var is a variable having only 0,1 values\n",
    "    N_1 = sum(var)\n",
    "    N = len(var)\n",
    "    N_0 = N - N_1\n",
    "    return 0 if N_0==0 or N_1==0 else - N_1/N * math.log(N_1/N, 2) - N_0/N * math.log(N_0/N, 2)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "DTM = vectorizer.fit_transform(trainingcorpus)\n",
    "#Now, to transorm it in an occurrence matrix, where the term is not 0, we put a 1.\n",
    "npDTM = np.array(DTM.toarray())\n",
    "npDTM[npDTM != 0] = 1\n",
    "\n",
    "labels = np.array(dataset['label'])\n",
    "\n",
    "entropy_label = entropy(labels)\n",
    "\n",
    "features_IG = pandas.DataFrame(data = {'feature': [], 'IG': []})\n",
    "\n",
    "for column in npDTM.T:\n",
    "    N_1 = len(labels[column==1])\n",
    "    N_0 = len(labels[column==0])\n",
    "    N = N_1 + N_0\n",
    "    IG = entropy_label - N_1/N * entropy(labels[column==1]) - N_0/N * entropy(labels[column==0])\n",
    "    features_IG = features_IG.append(pandas.DataFrame([[\"\", IG]], columns=['feature','IG']), ignore_index=True)\n",
    "\n",
    "features_IG['feature'] = vectorizer.get_feature_names()\n",
    "\n",
    "print(features_IG.sort_values('IG', ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Train Neural Net using only the 50 attributes with highest information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top 50 IG\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
