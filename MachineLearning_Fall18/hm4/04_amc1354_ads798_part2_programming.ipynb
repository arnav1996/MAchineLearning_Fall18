{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW04 Machine Learning Fall 2018 | Part II - Programming | amc1354 & ads798\n",
    "## Problem 5\n",
    "### (a) List the 5 tokens that occur most frequently in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most frequent tokens:\n",
      " [('.', 1426), (',', 1349), ('the', 1255), ('a', 938), ('and', 919)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"reviewstrain.txt\") as f:\n",
    "    traindata=[line.split() for line in f]\n",
    "\n",
    "dataset = pd.DataFrame(data = {'review': [' '.join(traindata[0][1:])], 'label': [int(traindata[0][0])]})\n",
    "for item in traindata[1:]:\n",
    "    dataset = dataset.append(pd.DataFrame([[' '.join(item[1:]), int(item[0])]], columns=['review','label']), ignore_index=True)\n",
    "\n",
    "token_count = Counter(' '.join(dataset['review']).split()).most_common()\n",
    "print(\"Top 5 most frequent tokens:\\n\", token_count[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the most frequent tokens are English stopwords and punctuation. One could create a more useful dataset by removing punctuation, English stopwords, and stemming words so we don't have attributes with repeated meaning. E.g., \"love\", \"loved\", \"loving\" would form different attributes. After stemming, they will belong to the same attribute \"lov\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Calculate IG for every attribute and list the 5 attributes with the highest IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature        IG\n",
      "399      bad  0.025357\n",
      "487     best  0.020668\n",
      "5098     too  0.011856\n",
      "3228  moving  0.011615\n",
      "225      and  0.010230\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import numpy as np\n",
    "def entropy(var):\n",
    "    #var is a variable having only 0,1 values\n",
    "    N_1 = sum(var)\n",
    "    N = len(var)\n",
    "    N_0 = N - N_1\n",
    "    return 0 if N_0==0 or N_1==0 else - N_1/N * math.log(N_1/N, 2) - N_0/N * math.log(N_0/N, 2)\n",
    "\n",
    "trainingcorpus = dataset['review']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "DTM = vectorizer.fit_transform(trainingcorpus)\n",
    "#Now, to transorm it in an occurrence matrix, where the term is not 0, we put a 1.\n",
    "npDTM = np.array(DTM.toarray())\n",
    "npDTM[npDTM != 0] = 1\n",
    "\n",
    "labels = np.array(dataset['label'])\n",
    "\n",
    "entropy_label = entropy(labels)\n",
    "\n",
    "features_IG = pd.DataFrame(data = {'feature': [], 'IG': []})\n",
    "\n",
    "for column in npDTM.T:\n",
    "    N_1 = len(labels[column==1])\n",
    "    N_0 = len(labels[column==0])\n",
    "    N = N_1 + N_0\n",
    "    IG = entropy_label - N_1/N * entropy(labels[column==1]) - N_0/N * entropy(labels[column==0])\n",
    "    features_IG = features_IG.append(pd.DataFrame([[\"\", IG]], columns=['feature','IG']), ignore_index=True)\n",
    "\n",
    "features_IG['feature'] = vectorizer.get_feature_names()\n",
    "\n",
    "print(features_IG.sort_values('IG', ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Train Neural Net using only the 50 attributes with highest information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bppy_logloss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f4a34569ed4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbppy_logloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_top_IG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_IG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bppy_logloss'"
     ]
    }
   ],
   "source": [
    "import bppy_logloss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k=50\n",
    "training_top_IG = features_IG.sort_values('IG', ascending=False)[:k]['feature']\n",
    "\n",
    "I = npDTM[:,training_top_IG.index.values]\n",
    "D = labels.reshape([-1,1])\n",
    "n_hidden = 10\n",
    "eta = 0.1\n",
    "n_max = 400\n",
    "\n",
    "w,wb,v,vb,err_curve = bppy_logloss.bp(I,D,n_hidden,eta,n_max)\n",
    "\n",
    "#predict\n",
    "with open(\"reviewstest.txt\") as f:\n",
    "    testdata=[line.split() for line in f]\n",
    "\n",
    "testdataset = pd.DataFrame(data = {'review': [' '.join(testdata[0][1:])], 'label': [int(testdata[0][0])]})\n",
    "for item in testdata[1:]:\n",
    "    testdataset = testdataset.append(pd.DataFrame([[' '.join(item[1:]), int(item[0])]], columns=['review','label']), ignore_index=True)\n",
    "\n",
    "testcorpus = testdataset['review']\n",
    "\n",
    "testDTM = vectorizer.fit_transform(testcorpus)\n",
    "nptestDTM = np.array(testDTM.toarray())\n",
    "nptestDTM[nptestDTM != 0] = 1\n",
    "\n",
    "test_features=vectorizer.get_feature_names()\n",
    "training_features = np.array(training_top_IG)\n",
    "\n",
    "testI = np.empty((500,0), int)\n",
    "\n",
    "for feature in training_features:\n",
    "    if feature in test_features:\n",
    "        testI = np.append(testI, nptestDTM[:,test_features.index(feature)].reshape([-1,1]), axis=1)\n",
    "    else:\n",
    "        testI = np.append(testI, np.zeros(500).reshape([-1,1]), axis=1)\n",
    "\n",
    "\n",
    "y_pred = np.empty((0,0), int)\n",
    "for i in range(500):\n",
    "    x = testI[i,:].reshape([1,-1])\n",
    "    z = bppy_logloss.sigmoid(x.dot(w)+wb)\n",
    "    y_pred = np.append(y_pred, 0 if bppy_logloss.sigmoid(z.dot(v)+vb)<=.5 else 1)\n",
    "    \n",
    "\n",
    "y_test = pd.Series(testdataset['label'])\n",
    "y_pred = pd.Series(y_pred)\n",
    "cm = pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)\n",
    "\n",
    "print(\"\\n Confusion matrix for top {} IG tokens:\\n\\n\".format(k), cm)\n",
    "print(\"\\n Accuracy = {}%\".format(100*(cm[0][0]+cm[1][1])/cm['All']['All']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We played with few values of eta (learning rate) and n_max (number of epochs). We noted that for low values of eta, say 0.001, bacward propagation too long (many, many epochs) to find a minimum. Keeping the same number of epochs, 0.1 is a more appropriate learning rate then eta=0.001 or 0.01 as the latter values achieved a lower accuracy. Regarding the number of epochs, we settled at 400 because by looking at the plot above (y shows the mean training error and x shows the no. of epoch) for 1,000 epochs, it looked like plateauing at roughly 400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Accuracy achieved by Zero-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy using zero-r = 54.6%\n"
     ]
    }
   ],
   "source": [
    "# Apply Zero-R algorithm\n",
    "y_train = []\n",
    "for review in traindata:\n",
    "    y_train.append(int(review[0]))\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "if sum(y_train==0) <= sum(y_train==1):\n",
    "    pred_zr = 1\n",
    "else:\n",
    "    pred_zr = 0\n",
    "    \n",
    "Nt = len(y_test)\n",
    "y_pred_zr = [pred_zr]*Nt \n",
    "\n",
    "print(\"\\n Accuracy using zero-r = {}%\".format(100*sum(y_test==y_pred_zr)/Nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Using Top k attributes\n",
    "\n",
    "It would be reasonable to think that by including more attributes we add more information. Therefore, accuracy should increase as we include more tokens.\n",
    "\n",
    "The contrary might be reasonable as well: including less attributes lower the computational burden. Moreover, including more attributes means also including more noise so we might need to restructure the network by adding more layers and playing with the no. of nodes per layer to capture the level of complexity of the decision function. Finally, we expect the IG to plateau or approach 0 in the least attributes ranked by IG levels. So there might be a threshold of the number of attributes such that including more does not improve accuracy substantially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Experiments With Top k attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58.8 63.  66.6 69.4 71.8]\n"
     ]
    }
   ],
   "source": [
    "accuracy_curve = np.array([])\n",
    "for k in [10, 20, 50, 100, 200]:\n",
    "    \n",
    "    training_top_IG = features_IG.sort_values('IG', ascending=False)[:k]['feature']\n",
    "\n",
    "    I = npDTM[:,training_top_IG.index.values]\n",
    "    D = labels.reshape([-1,1])\n",
    "    n_hidden = 10\n",
    "    eta = 0.1\n",
    "    n_max = 400\n",
    "\n",
    "    w,wb,v,vb,err_curve = bppy_logloss.bp(I, D, n_hidden, eta, n_max, \"no plot\")\n",
    "\n",
    "    training_features = np.array(training_top_IG)\n",
    "\n",
    "    testI = np.empty((500,0), int)\n",
    "\n",
    "    for feature in training_features:\n",
    "        if feature in test_features:\n",
    "            testI = np.append(testI, nptestDTM[:,test_features.index(feature)].reshape([-1,1]), axis=1)\n",
    "        else:\n",
    "            testI = np.append(testI, np.zeros(500).reshape([-1,1]), axis=1)\n",
    "\n",
    "    y_pred = np.empty((0,0), int)\n",
    "    for i in range(500):\n",
    "        x = testI[i,:].reshape([1,-1])\n",
    "        z = bppy_logloss.sigmoid(x.dot(w)+wb)\n",
    "        y_pred = np.append(y_pred, 0 if bppy_logloss.sigmoid(z.dot(v)+vb)<=.5 else 1)\n",
    "    \n",
    "    y_test = pd.Series(testdataset['label'])\n",
    "    y_pred = pd.Series(y_pred)\n",
    "    cm = pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)\n",
    "\n",
    "    accuracy_curve = np.append(accuracy_curve, 100*(cm[0][0]+cm[1][1])/cm['All']['All'])\n",
    "    \n",
    "plt.plot([10, 20, 50, 100, 200], accuracy_curve)        \n",
    "plt.show()\n",
    "\n",
    "print(accuracy_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot has the accuracy in % on the Y axis and the no. of k top-IG attributes used on the X axis. We expected to see accuracy increasing by including more information. However, we did not expect such a big increase from 50 attributes to 200 (accuracy improves of 5.2 percentage points) as the Nnet we used has just 10 nodes in the middle layers. It would be interesting to plot the ranked IG values to see when and if it has a plateau so to verify how many tokens it is sensible including. \n",
    "\n",
    "Regarding difficulties running the experiments, we observed training times increasing with the number of attributes. This is expected as there are many more weights to run GD epochs on. 200 was the limit for running the code on our local laptop in a reasonable time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
